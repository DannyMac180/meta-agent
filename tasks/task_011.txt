# Task ID: 11
# Title: Implement Tool Designer Sub-agent
# Status: in-progress
# Dependencies: 3, 4
# Priority: high
# Description: Designs and generates code for tools required by the agent based on the specification
# Details:


# Test Strategy:


# Subtasks:
## 1. Create Tool Specification Parser [done]
### Dependencies: None
### Description: Develop a module that can parse and validate tool specifications provided by users or other agents, extracting key information needed for tool generation.
### Details:
Implementation details:
1. Create a `ToolSpecificationParser` class that can accept tool specifications in various formats (JSON, YAML, or structured text)
2. Implement validation logic to ensure specifications contain required fields (name, purpose, input parameters, output format)
3. Add methods to extract and normalize tool requirements from specifications
4. Include error handling for malformed specifications
5. Create unit tests with various specification formats to verify parsing accuracy
6. Test with edge cases like missing fields, unusual parameter types

Testing approach:
- Create a test suite with sample tool specifications in different formats
- Verify parser correctly extracts all required information
- Test error handling with deliberately malformed specifications

## 2. Implement Tool Code Generator [done]
### Dependencies: 11.1
### Description: Build a code generation system that can transform parsed tool specifications into executable Python code implementing the requested tool functionality.
### Details:
Implementation details:
1. Create a `ToolCodeGenerator` class that accepts parsed tool specifications
2. Implement template-based code generation for common tool patterns
3. Add support for different tool types (API callers, data processors, etc.)
4. Include docstring and type hint generation in created tools
5. Implement validation of generated code (syntax checking)
6. Add unit tests to verify code generation quality
7. Create a mechanism to handle dependencies required by generated tools

Testing approach:
- Generate code for a variety of tool types and verify syntax correctness
- Test generated tools with sample inputs to verify functionality
- Verify proper error handling in generated code
- Check that generated code follows best practices (type hints, documentation)

## 3. Create Tool Designer Agent Interface [done]
### Dependencies: 11.1, 11.2
### Description: Develop the main Tool Designer sub-agent that coordinates the specification parsing and code generation, providing a unified interface for other parts of the system.
### Details:
Implementation details:
1. Create a `ToolDesignerAgent` class that orchestrates the tool design process
2. Implement methods to accept tool requests from other agents or users
3. Add workflow logic to: parse specifications, generate code, test generated tools
4. Include feedback mechanisms for reporting success/failure of tool creation
5. Implement tool registration with the main agent system
6. Add caching of previously designed tools to avoid regeneration
7. Create comprehensive logging of the tool design process
8. Develop integration tests for the complete workflow

Testing approach:
- Test end-to-end workflow with various tool specifications
- Verify proper integration with the main agent system
- Test error handling and recovery mechanisms
- Verify logging and monitoring capabilities
- Test performance with complex tool specifications

## 4. Create Tool Designer Sub-agent Framework [done]
### Dependencies: None
### Description: Implement the base structure for the Tool Designer sub-agent that will be responsible for generating tool code based on specifications
### Details:
Implementation steps:
1. Create a new class `ToolDesignerAgent` with appropriate interfaces and abstract methods
2. Define the core data structures needed for tool specifications (input/output parameters, description, etc.)
3. Implement the communication interface between the main agent and this sub-agent
4. Create a structured template system for tool code generation with placeholders for implementation details
5. Add configuration options for the Tool Designer
6. Implement basic validation for tool specifications

Testing approach:
- Unit test the template system with mock implementations
- Verify the data structures correctly represent tool specifications
- Test the communication interface with mock messages

## 5. Implement LLM-backed Code Generation for Tools [done]
### Dependencies: None
### Description: The core framework for LLM-backed code generation for tools is implemented (see LLMCodeGenerator and its components). Current focus for this task is to ensure LLMService correctly integrates with the intended LLM provider endpoints (e.g., standard OpenAI /v1/chat/completions vs. the currently implemented /v1/responses endpoint), including request/response handling and code extraction logic in _extract_code_from_response.
### Details:
Implementation steps:
1. Design effective prompts for the LLM to generate tool implementation code based on specifications
2. Implement a service to handle LLM API calls with appropriate error handling and retries
3. Create a context builder that provides relevant information to the LLM (tool purpose, input/output formats, constraints)
4. Implement code parsing and validation to ensure generated code meets requirements
5. Add a mechanism to inject the generated implementation into the tool template
6. Implement fallback strategies for when code generation fails

Testing approach:
- Test the prompt effectiveness with various tool types
- Verify generated code compiles and functions correctly
- Test error handling and fallbacks
- Create integration tests with sample tool specifications

## 6. Integrate Tool Designer with Main Agent Workflow [pending]
### Dependencies: None
### Description: Connect the Tool Designer sub-agent with the main agent workflow and implement the end-to-end process for tool creation
### Details:
Implementation steps:
1. Implement the main workflow for tool creation: specification → code generation → validation → registration
2. Add functionality to dynamically load and register newly created tools with the main agent
3. Implement a caching mechanism for previously generated tools to avoid redundant generation
4. Create a feedback loop mechanism where the main agent can request modifications to tools
5. Add logging and monitoring for the tool generation process
6. Implement versioning for generated tools
7. Create a user interface or API endpoint for manual tool specification submission

Additional Implementation Guidance:
These notes clarify design expectations so the coding agent can move quickly without ambiguity.

Overall control-flow (happy path):
User / Upstream-Agent → MetaAgentOrchestrator → PlanningEngine → SubAgentManager →
   ToolDesignerAgent  ─┐
                       │  (1) design_tool_with_llm / design_tool
                       ▼
                GeneratedTool artefact
                       │  (2) Validation (CodeValidator + SandboxManager)
                       ▼
           ToolRegistry.register(generated_tool)
                       │  (3) return handle / module path
                       ▼
          Orchestrator pipelines tool into next task

1. Workflow implementation:
   - Add a new method `create_tool(spec: ToolSpec) -> GeneratedToolHandle` in `SubAgentManager` that wraps the full pipeline (parse → generate → validate → register).
   - Extend `MetaAgentOrchestrator.handle_task()` to call this helper whenever a tool-design task bubble is detected in the plan tree.

2. Tool registration & dynamic loading:
   - Introduce `ToolRegistry` under `src/meta_agent/registry.py` with APIs:
     class ToolRegistry:
         def register(tool: GeneratedTool, version: str) -> str:  # returns fully-qualified module path
         def get(name: str, version: str | None = None) -> ModuleType | None
         def latest(name: str) -> ModuleType | None
   - Registration writes the tool's Python file into `src/.tool_designer/artefacts/<tool_name>/<version>/tool.py` and uses `importlib.util.module_from_spec` to load it at runtime.
   - Maintain `registry.json` manifest (tool → versions → path, checksum, created_at).

3. Caching:
   - Compute `spec_fingerprint = sha256(normalised_spec_json)[:16]`.
   - Before generation look up `<tool_name>/<spec_fingerprint>` in the manifest; if present, reuse path.

4. Feedback loop:
   - Provide an `update_tool(tool_name, modifications)` method which sends a refine request back to `ToolDesignerAgent` with the original spec + diff instructions.
   - Store last N revisions per tool; bump version (major.minor.patch or timestamp) each time.

5. Logging & monitoring:
   - Emit structured JSON logs at INFO for each stage with keys: tool, event, duration_ms, success.
   - Capture metrics counters: tool_generated_total, tool_generation_failed_total, tool_cached_hit_total.

6. Versioning strategy:
   - Default 0.1.0 for first generation.
   - Minor bump for non-breaking edits (feedback loop).
   - Major bump if input/output contract changes (detected via spec diff on IO definition section).

7. UI / API consideration:
   - Expose a new CLI command: `meta-agent tool create path/to/spec.yaml --use-llm`.
   - In future a lightweight FastAPI service can proxy spec submissions; design interfaces accordingly but CLI is MVP.

Acceptance Criteria:
- `tests/integration/test_tool_lifecycle.py` demonstrates end-to-end creation, caching hit, and registry load.
- Tools appear in manifest with correct metadata and can be imported and executed.
- Generating the same spec twice results in a cache hit (no LLM call).
- Feedback update bumps version and registry returns the latest by default.

Testing approach:
- End-to-end testing with sample specifications
- Verify tools are correctly registered and usable by the main agent
- Test the modification and feedback loop process
- Performance testing for tool generation time
- Test caching mechanisms work correctly

## 7. Create Tool Designer Sub-agent Core Structure [pending]
### Dependencies: None
### Description: Implement the base structure for the Tool Designer sub-agent that will be responsible for generating code for tools based on specifications.
### Details:
Implementation details:

1. Create a new class `ToolDesignerAgent` that extends the base agent class with the following components:
   - Constructor that accepts tool specifications and configuration parameters
   - Methods for parsing and validating tool specifications
   - Core prompt templates for tool design and code generation
   - State management for tracking the design process

2. Implement the main execution flow:
   - Analyze tool specification requirements
   - Generate a design plan for the requested tool
   - Structure the code generation process
   - Return the generated tool code

3. Add configuration options for:
   - Code style preferences
   - Documentation requirements
   - Language/framework specifications
   - Testing requirements

Testing approach:
- Unit test the agent initialization and configuration
- Test specification parsing with various input formats
- Verify the agent can process basic tool specifications

## 8. Implement Web Search Integration for Tool Research [pending]
### Dependencies: None
### Description: Add capabilities for the Tool Designer to leverage web search for researching APIs, code examples, and existing tools to improve code generation.
### Details:
Implementation details:

1. Integrate OpenAI Responses API [web] tool or equivalent search capability:
   - Create a `ToolResearchManager` class that handles web searches
   - Implement methods to formulate search queries based on tool specifications
   - Add functionality to extract and process relevant information from search results

2. Enhance the Tool Designer with research capabilities:
   - Add a research phase before code generation
   - Implement methods to search for:
     * Relevant APIs and documentation
     * Code examples and patterns
     * Existing tools with similar functionality
     * Best practices for the specific tool type

3. Make the research process configurable:
   - Add options to enable/disable web search
   - Configure search depth and breadth
   - Set relevance thresholds for incorporating found information
   - Add caching mechanisms for search results

Testing approach:
- Test search query generation with various tool specifications
- Verify proper extraction of relevant information from search results
- Test the integration of search results into the code generation process
- Benchmark performance with and without web search integration

## 9. Implement Code Generation and Testing Capabilities [pending]
### Dependencies: None
### Description: Develop the core code generation functionality with testing and validation capabilities to ensure the generated tools work as expected.
### Details:
Implementation details:

1. Implement advanced code generation:
   - Create a `ToolCodeGenerator` class that uses LLM to generate code based on specifications and research
   - Add support for multiple programming languages and frameworks
   - Implement structured generation for different tool components (interfaces, implementation, utilities)
   - Include proper error handling and documentation in generated code

2. Add code validation and testing capabilities:
   - Implement static code analysis to verify syntax and structure
   - Generate unit tests for the created tools
   - Create a sandbox environment for basic runtime validation
   - Add self-correction mechanisms for when validation fails

3. Implement tool packaging and integration:
   - Generate necessary package metadata (requirements, dependencies)
   - Create installation/usage instructions
   - Provide integration examples for the main agent system
   - Add versioning support for generated tools

Testing approach:
- Test code generation with various tool specifications
- Verify the quality of generated code against best practices
- Test the validation and testing mechanisms
- Ensure generated tools can be properly integrated into the main agent system
- Perform end-to-end testing with sample tool specifications
